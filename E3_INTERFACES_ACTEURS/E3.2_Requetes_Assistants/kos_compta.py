"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  KOS_COMPTA : GÃ©nÃ©rateur d'Ã‰critures Comptables pour ERP   â•‘
â•‘  Pipeline E4 : Payloads JSON â†’ CSV Import CEGID             â•‘
â•‘  Version : 2.0.0 â€” Production-Ready                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONTEXTE :
    Ce script est le maillon final du pipeline KOS_COMPTA.
    Il transforme les verdicts JSON produits par l'agent de conformitÃ©
    (Ã©tape E4.2) en un fichier CSV normalisÃ©, prÃªt Ã  Ãªtre importÃ©
    dans un ERP comptable type CEGID.

PIPELINE KOS_COMPTA (vue macro) :
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ E4.1 Audit  â”‚ â”€â”€â–º â”‚ E4.2 Payload â”‚ â”€â”€â–º â”‚ E4.3 Import    â”‚
    â”‚ (Verdict IA)â”‚     â”‚ (JSON struct)â”‚     â”‚ (CSV â†’ CEGID)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â–²
                                              CE SCRIPT

ARCHITECTURE DES Ã‰CRITURES GÃ‰NÃ‰RÃ‰ES :
    Pour chaque facture validÃ©e, le script produit jusqu'Ã  3 lignes :

    1. Ligne HT   (DÃ©bit)  â†’ Compte de charge (ex: 62888)
    2. Ligne TVA  (DÃ©bit)  â†’ Compte 44566 (TVA dÃ©ductible sur ABS)
    3. Ligne TTC  (CrÃ©dit) â†’ Compte fournisseur (ex: 401)

    ContrÃ´le de sÃ©curitÃ© : HT + TVA â‰ˆ TTC (math.isclose)

GARANTIES v2.0 :
    âœ… ContrÃ´le d'intÃ©gritÃ© comptable (partie double vÃ©rifiÃ©e)
    âœ… Archivage transactionnel (aucune perte de donnÃ©e en cas de crash)
    âœ… Validation de structure JSON (batch rÃ©silient, pas de crash total)

FICHIERS MANIPULÃ‰S :
    EntrÃ©e  : E4_AUDIT_ET_ROUTAGE/E4.2_Payloads_ERP/*.json
    Sortie  : E4_AUDIT_ET_ROUTAGE/E4.3_Imports_ERP/IMPORT_CEGID_<timestamp>.csv
    Archive : E4_AUDIT_ET_ROUTAGE/E4.2_Payloads_ERP/archive/  (JSONs traitÃ©s)

STATUT  : Production-Ready (E2.1.1_SCRIPTS_TESTS)
VERSION : 2.0.0
AUTEUR  : KOS_COMPTA / ERGO
"""

import json
import csv
import math
import logging
from pathlib import Path
from datetime import datetime

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 0 : CONFIGURATION DU LOGGER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# On utilise le module logging natif Python plutÃ´t que de
# simples print() pour permettre la redirection vers fichier,
# le filtrage par sÃ©vÃ©ritÃ©, et l'intÃ©gration future avec
# registrar.py (le Greffier KOS).

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger("KOS_COMPTA")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 1 : CHEMINS DU SYSTÃˆME DE FICHIERS KOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RÃ©solution dynamique des chemins via Path(__file__).parent.parent
# pour rester agnostique Ã  l'emplacement d'installation.
#
# Arborescence attendue :
#   KOS ERGO/
#   â”œâ”€â”€ E4_AUDIT_ET_ROUTAGE/
#   â”‚   â”œâ”€â”€ E4.2_Payloads_ERP/       â† JSONs verdicts (entrÃ©e)
#   â”‚   â”‚   â””â”€â”€ archive/             â† JSONs dÃ©jÃ  exportÃ©s
#   â”‚   â””â”€â”€ E4.3_Imports_ERP/        â† CSVs gÃ©nÃ©rÃ©s (sortie)
#   â””â”€â”€ E2_INGÃ‰NIERIE & DATA/
#       â””â”€â”€ E2.1_GENIE_LOGICIEL/
#           â””â”€â”€ E2.1.1_SCRIPTS_TESTS/
#               â””â”€â”€ kos_compta/       â† CE SCRIPT

BASE_DIR = Path(__file__).parent.parent
PAYLOADS_DIR = BASE_DIR / "E4_AUDIT_ET_ROUTAGE" / "E4.2_Payloads_ERP"
EXPORT_DIR = BASE_DIR / "E4_AUDIT_ET_ROUTAGE" / "E4.3_Imports_ERP"
ARCHIVE_DIR = PAYLOADS_DIR / "archive"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION 2 : TOLÃ‰RANCE POUR LE CONTRÃ”LE D'INTÃ‰GRITÃ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TolÃ©rance en euros pour la vÃ©rification de la partie double.
# On utilise une tolÃ©rance absolue de 0.01â‚¬ (1 centime) pour
# absorber les erreurs d'arrondi flottant classiques.
# Ex: 100.00 + 20.00 devrait donner 120.00, mais en float
#     on peut obtenir 119.99999999999999 â€” d'oÃ¹ la tolÃ©rance.

TOLERANCE_EUROS = 0.01


def valider_structure_json(data: dict, chemin_fichier: Path) -> dict | None:
    """
    Valide la structure du payload JSON et extrait le bloc d'imputation.

    VÃ©rifie :
        1. PrÃ©sence de la clÃ© "verdict"
        2. PrÃ©sence de la clÃ© "imputation_recommandee" dans le verdict
        3. PrÃ©sence des champs obligatoires (montant_ht, montant_ttc)

    Args:
        data: Le dictionnaire JSON parsÃ©.
        chemin_fichier: Le Path du fichier source (pour les logs).

    Returns:
        Le dictionnaire d'imputation si valide, None sinon.
    """
    # â”€â”€ VÃ©rification niveau 1 : bloc verdict â”€â”€
    verdict_bloc = data.get("verdict")
    if not isinstance(verdict_bloc, dict):
        logger.warning(
            "âš ï¸  IGNORÃ‰ [%s] : ClÃ© 'verdict' absente ou invalide.",
            chemin_fichier.name
        )
        return None

    # â”€â”€ VÃ©rification niveau 2 : bloc imputation â”€â”€
    imputation = verdict_bloc.get("imputation_recommandee")
    if not isinstance(imputation, dict) or not imputation:
        logger.warning(
            "âš ï¸  IGNORÃ‰ [%s] : ClÃ© 'imputation_recommandee' absente ou vide.",
            chemin_fichier.name
        )
        return None

    # â”€â”€ VÃ©rification niveau 3 : champs obligatoires â”€â”€
    champs_requis = ["montant_ht", "montant_ttc"]
    for champ in champs_requis:
        if champ not in imputation or imputation[champ] is None:
            logger.warning(
                "âš ï¸  IGNORÃ‰ [%s] : Champ obligatoire '%s' manquant.",
                chemin_fichier.name, champ
            )
            return None

    return imputation


def verifier_integrite_comptable(
    montant_ht: float,
    tva: float,
    montant_ttc: float,
    chemin_fichier: Path
) -> bool:
    """
    ContrÃ´le de sÃ©curitÃ© : vÃ©rifie que HT + TVA â‰ˆ TTC.

    Utilise math.isclose() avec une tolÃ©rance absolue de 0.01â‚¬
    pour absorber les erreurs d'arrondi flottant.

    RÃ¨gle comptable fondamentale de la partie double :
        Somme(DÃ©bits) = Somme(CrÃ©dits)
        âŸ¹ HT + TVA = TTC

    Args:
        montant_ht: Montant hors taxe.
        tva: TVA dÃ©ductible (peut Ãªtre 0).
        montant_ttc: Montant toutes taxes comprises.
        chemin_fichier: Le Path du fichier source (pour les logs).

    Returns:
        True si l'intÃ©gritÃ© est vÃ©rifiÃ©e, False sinon.
    """
    somme_debits = montant_ht + tva
    if not math.isclose(somme_debits, montant_ttc, abs_tol=TOLERANCE_EUROS):
        ecart = abs(somme_debits - montant_ttc)
        logger.error(
            "ğŸš« REJETÃ‰ [%s] : IntÃ©gritÃ© comptable violÃ©e ! "
            "HT(%.2f) + TVA(%.2f) = %.2f â‰  TTC(%.2f) â€” Ã‰cart: %.2fâ‚¬",
            chemin_fichier.name,
            montant_ht, tva, somme_debits, montant_ttc, ecart
        )
        return False
    return True


def main():
    """
    Point d'entrÃ©e principal â€” Version 2.0 Production-Ready.
    Orchestre le pipeline : Scan JSON â†’ Validation â†’ GÃ©nÃ©ration CSV â†’ Archivage.

    Flow :
        1. CrÃ©er les dossiers de sortie s'ils n'existent pas
        2. Scanner les payloads JSON dans E4.2
        3. Pour chaque JSON :
           a. Valider la structure (try/except + validation logique)
           b. VÃ©rifier l'intÃ©gritÃ© comptable HT + TVA â‰ˆ TTC
           c. GÃ©nÃ©rer les Ã©critures comptables (HT/TVA/TTC)
        4. Ã‰crire et fermer le fichier CSV
        5. Archiver en bloc les JSONs traitÃ©s (transactionnel)
        6. Afficher le rapport de synthÃ¨se
    """
    print("â•" * 60)
    print(" ğŸ­ KOS_COMPTA v2.0 : GÃ‰NÃ‰RATION DU FICHIER ERP")
    print("â•" * 60)

    # â”€â”€ Ã‰tape 1 : Initialisation des rÃ©pertoires â”€â”€
    # mkdir(parents=True) crÃ©e toute la chaÃ®ne de dossiers si nÃ©cessaire
    # exist_ok=True Ã©vite l'erreur si le dossier existe dÃ©jÃ 
    EXPORT_DIR.mkdir(parents=True, exist_ok=True)
    ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)

    # â”€â”€ Ã‰tape 2 : DÃ©couverte des payloads Ã  traiter â”€â”€
    # On ne prend que les .json Ã  la racine de E4.2 (pas dans /archive)
    fichiers_json = list(PAYLOADS_DIR.glob("*.json"))

    if not fichiers_json:
        logger.info("âš ï¸ Aucun nouveau payload JSON Ã  exporter vers l'ERP.")
        return

    logger.info("ğŸ“¥ %d payload(s) JSON dÃ©tectÃ©(s) dans E4.2.", len(fichiers_json))

    # â”€â”€ Ã‰tape 3 : CrÃ©ation du fichier CSV d'export â”€â”€
    # Le timestamp garantit l'unicitÃ© du fichier et la traÃ§abilitÃ© temporelle
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = EXPORT_DIR / f"IMPORT_CEGID_{timestamp}.csv"

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMPTEURS DE SYNTHÃˆSE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lignes_exportees = 0
    fichiers_rejetes = 0
    fichiers_ignores = 0

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # LISTE D'ARCHIVAGE TRANSACTIONNEL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # On NE dÃ©place PAS les fichiers pendant la boucle de lecture.
    # On stocke les chemins des fichiers traitÃ©s avec succÃ¨s,
    # et on les archive EN BLOC Ã  la fin, aprÃ¨s fermeture du CSV.
    # Garantie : si le script plante mid-loop, aucun JSON n'est
    # dÃ©placÃ© â†’ on peut relancer sans perte de donnÃ©es.
    fichiers_a_archiver: list[Path] = []

    # â”€â”€ Ã‰tape 4 : GÃ©nÃ©ration des Ã©critures comptables â”€â”€
    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:
        writer = csv.writer(csv_file, delimiter=';')

        # En-tÃªte CSV normalisÃ© pour import ERP
        # DATE      : Date de l'Ã©criture (JJ/MM/AAAA)
        # JOURNAL   : Code journal comptable (ACH = Achats)
        # COMPTE    : NumÃ©ro de compte PCG
        # SENS      : D = DÃ©bit, C = CrÃ©dit
        # MONTANT   : Montant en euros
        # LIBELLE   : Description de l'opÃ©ration
        # STATUT_KOS: Verdict de l'agent IA (CONFORME / A_VALIDER / REJET)
        writer.writerow([
            "DATE", "JOURNAL", "COMPTE", "SENS",
            "MONTANT", "LIBELLE", "STATUT_KOS"
        ])

        for path in fichiers_json:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # GARDE 1 : Validation de lecture JSON
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # try/except empÃªche un JSON malformÃ© de faire
            # crasher le batch entier. On log et on continue.
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            except json.JSONDecodeError as e:
                logger.error(
                    "ğŸš« ERREUR [%s] : JSON malformÃ© â€” %s",
                    path.name, str(e)
                )
                fichiers_rejetes += 1
                continue
            except OSError as e:
                logger.error(
                    "ğŸš« ERREUR [%s] : Impossible de lire le fichier â€” %s",
                    path.name, str(e)
                )
                fichiers_rejetes += 1
                continue

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # GARDE 2 : Validation de structure JSON
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # VÃ©rifie la prÃ©sence et la validitÃ© des clÃ©s
            # obligatoires (verdict, imputation, montants).
            imputation = valider_structure_json(data, path)
            if imputation is None:
                fichiers_ignores += 1
                continue

            # Extraction des donnÃ©es validÃ©es
            verdict_bloc = data["verdict"]
            action_erp = verdict_bloc.get("action_erp", "A_VALIDER")

            montant_ht = float(imputation.get("montant_ht", 0))
            tva = float(imputation.get("tva_deductible", 0))
            montant_ttc = float(imputation.get("montant_ttc", 0))

            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # GARDE 3 : ContrÃ´le d'intÃ©gritÃ© comptable
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # VÃ©rifie la rÃ¨gle fondamentale de la partie double :
            #   Î£ DÃ©bits = Î£ CrÃ©dits  âŸ¹  HT + TVA â‰ˆ TTC
            # Si cette rÃ¨gle est violÃ©e, la facture est
            # mathÃ©matiquement fausse â†’ on ne l'Ã©crit PAS.
            if not verifier_integrite_comptable(montant_ht, tva, montant_ttc, path):
                fichiers_rejetes += 1
                continue

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # GÃ‰NÃ‰RATION DES Ã‰CRITURES (3 gardes passÃ©es âœ“)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

            date_jour = datetime.now().strftime("%d/%m/%Y")
            libelle = f"Achat - {path.stem.replace('PAYLOAD_', '')}"

            # â”€â”€ Ã‰criture 1 : Ligne HT (DÃ©bit charge) â”€â”€
            # DÃ©bite le compte de charge du montant HT
            # Valeur par dÃ©faut 62888 si aucun compte spÃ©cifiÃ© par l'IA
            if montant_ht:
                writer.writerow([
                    date_jour,
                    "ACH",
                    imputation.get("compte_debit", "62888"),
                    "D",
                    f"{montant_ht:.2f}",
                    libelle,
                    action_erp
                ])
                lignes_exportees += 1

            # â”€â”€ Ã‰criture 2 : Ligne TVA dÃ©ductible (DÃ©bit) â”€â”€
            # Compte 44566 = TVA dÃ©ductible sur autres biens et services
            # N'Ã©crit la ligne QUE si TVA > 0 (principe de non-Ã©criture Ã  zÃ©ro)
            if tva > 0:
                writer.writerow([
                    date_jour,
                    "ACH",
                    "44566",
                    "D",
                    f"{tva:.2f}",
                    libelle,
                    action_erp
                ])
                lignes_exportees += 1

            # â”€â”€ Ã‰criture 3 : Ligne TTC (CrÃ©dit fournisseur) â”€â”€
            # CrÃ©dite le fournisseur du montant TTC
            # Valeur par dÃ©faut 401 (Fournisseurs) si non spÃ©cifiÃ©
            if montant_ttc:
                writer.writerow([
                    date_jour,
                    "ACH",
                    imputation.get("compte_credit", "401"),
                    "C",
                    f"{montant_ttc:.2f}",
                    libelle,
                    action_erp
                ])
                lignes_exportees += 1

            # â”€â”€ Marquer pour archivage (PAS de rename ici !) â”€â”€
            fichiers_a_archiver.append(path)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ã‰TAPE 5 : ARCHIVAGE TRANSACTIONNEL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Le CSV est maintenant fermÃ© (context manager `with` terminÃ©).
    # On peut archiver les JSONs en toute sÃ©curitÃ© : si le script
    # avait plantÃ© pendant l'Ã©criture CSV, les JSONs seraient
    # restÃ©s en place pour une nouvelle tentative.

    archives_reussies = 0
    for path in fichiers_a_archiver:
        try:
            path.rename(ARCHIVE_DIR / path.name)
            archives_reussies += 1
        except OSError as e:
            logger.error(
                "âš ï¸  ARCHIVAGE Ã‰CHOUÃ‰ [%s] : %s",
                path.name, str(e)
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ã‰TAPE 6 : RAPPORT DE SYNTHÃˆSE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print()
    print("â•" * 60)
    print(" ğŸ“Š RAPPORT D'EXÃ‰CUTION KOS_COMPTA v2.0")
    print("â•" * 60)
    print(f"  ğŸ“¥ Payloads dÃ©tectÃ©s   : {len(fichiers_json)}")
    print(f"  âœ… Ã‰critures gÃ©nÃ©rÃ©es  : {lignes_exportees}")
    print(f"  ğŸ“¦ Fichiers archivÃ©s   : {archives_reussies}")
    print(f"  âš ï¸  Fichiers ignorÃ©s    : {fichiers_ignores}")
    print(f"  ğŸš« Fichiers rejetÃ©s    : {fichiers_rejetes}")
    print(f"  ğŸ“‚ Fichier ERP         : {csv_filename.name}")
    print("â•" * 60)

    if fichiers_rejetes > 0:
        logger.warning(
            "âš ï¸  %d fichier(s) rejetÃ©(s) â€” consultez les logs ci-dessus.",
            fichiers_rejetes
        )


if __name__ == "__main__":
    main()
